<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Mono3D Detection 整理, Untitled.">
    <meta name="description" content="本文整理了单目3D目标检测的相关工作
0.Introduction of 3D Object Detection在缺乏深度信息的情况下，根据RGB图像恢复3D结构是一个不适定问题。但是在提供先验信息的情况下，这个任务也能取得不错的效果。在具">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Mono3D Detection 整理 | Untitled.</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    


    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 6.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Untitled.</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Untitled.</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/massive11" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/massive11" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/9.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Mono3D Detection 整理</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Mono3D/">
                                <span class="chip bg-color">Mono3D</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E7%B3%BB%E7%BB%9F%E6%A2%B3%E7%90%86/" class="post-category">
                                系统梳理
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2022-08-12
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    2.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    11 分
                </div>
                

                
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.min.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <p>本文整理了单目3D目标检测的相关工作<br><span id="more"></span></p>
<h1 id="0-Introduction-of-3D-Object-Detection"><a href="#0-Introduction-of-3D-Object-Detection" class="headerlink" title="0.Introduction of 3D Object Detection"></a>0.Introduction of 3D Object Detection</h1><p>在缺乏深度信息的情况下，根据RGB图像恢复3D结构是一个不适定问题。但是在提供先验信息的情况下，这个任务也能取得不错的效果。<br>在具体的方案实现上，总体可以分为四条路线：</p>
<ol>
<li>Proposal-based的方案，先生成3D proposal ，再根据设定的方案对proposal进行排序，从而得到最后的结果</li>
<li>RGB-only的方案，将3D框的各组成项解耦，直接从RGB中回归各组成项再组合成3D框</li>
<li>Perspective transformation的方案，将原始的输入图像换一种表达形式（此处不包含借助depth进行3D结构恢复的方案）</li>
<li>Pseudo-LiDAR的方案 ，本质上都是在RGB图像上进行深度估计，恢复3D结构，然后在视觉点云上进行3D检测</li>
</ol>
<p>以下将一些代表性的论文粗略分为上述四个类别，按照时间线进行简单的回顾。</p>
<h1 id="1-Proposal-based"><a href="#1-Proposal-based" class="headerlink" title="1.Proposal-based"></a>1.Proposal-based</h1><h2 id="2016—CVPR—Mono3D"><a href="#2016—CVPR—Mono3D" class="headerlink" title="2016—CVPR—Mono3D"></a>2016—CVPR—Mono3D</h2><p>[<a target="_blank" rel="noopener" href="https://www.cs.toronto.edu/~urtasun/publications/chen_etal_cvpr16.pdf">Paper</a>]     [Code]</p>
<blockquote>
<p>Mono3D first samples candidates based on the ground prior and scores them with semantic/instance segmentation, contextual information, object shape, and location prior.<br>MonoFlex</p>
</blockquote>
<p>在3D空间中生成proposal，投影回2D后结合分割、形状、位置先验进行评分，最后保留的作为结果。</p>
<h2 id="2019—ICIP-Shift-RCNN"><a href="#2019—ICIP-Shift-RCNN" class="headerlink" title="2019—ICIP-Shift RCNN"></a>2019—ICIP-Shift RCNN</h2><p>[<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1905.09970.pdf">Paper</a>]     [Code]</p>
<blockquote>
<p>avoids dense proposal sampling by “actively” regressing the offset from the Deep3DBox proposal. They feed all the known 2D and 3D bbox info into a fast and simple fully connected network called ShiftNet and refine the 3D location</p>
</blockquote>
<h2 id="2019—ICCV—MonoDIS"><a href="#2019—ICCV—MonoDIS" class="headerlink" title="2019—ICCV—MonoDIS"></a>2019—ICCV—MonoDIS</h2><p>[<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1905.09970.pdf">Paper</a>]     [Code]</p>
<blockquote>
<p>Instead of directly supervising each of the components of 2D and 3D bbox output, it takes a holistic view of bbox regression and uses 2D (signed) IoU loss and 3D corner loss. These losses are hard to train in general, so it proposes a disentanglement technique by fixing all elements but one group (including one or more elements) to ground truth and calculate the loss, essentially training only parameters in that group.</p>
</blockquote>
<h2 id="2019—CVPR—MonoPSR"><a href="#2019—CVPR—MonoPSR" class="headerlink" title="2019—CVPR—MonoPSR"></a>2019—CVPR—MonoPSR</h2><blockquote>
<p>It generates 3D proposal first and then reconstructing local point cloud of dynamic objects.<br>The reconstruction branch regresses a local point cloud of the object and compares it with the GT in point cloud and camera (after projection).</p>
</blockquote>
<h2 id="2020—CVPR—D4LCN"><a href="#2020—CVPR—D4LCN" class="headerlink" title="2020—CVPR—D4LCN"></a>2020—CVPR—D4LCN</h2><blockquote>
<p>took the idea of depth-aware convolution from M3D-RPN even further by introducing a dynamic filter prediction branch. This additional branch which takes in the depth prediction as input and generates a filter feature volume, which generates different filters for each specific location in terms of both weights and dilation rates.</p>
</blockquote>
<h1 id="RGB-Image-only"><a href="#RGB-Image-only" class="headerlink" title="RGB Image only"></a>RGB Image only</h1><p>基于RGB图像直接得到3D框通常是通过借助关键点、目标形状、2D-3D的几何一致性约束等来进行3D框的解耦从而得到最后的结果。<br>关注的目标大尺寸大多有相似的尺寸，这个信息对于估计到目标的距离有很大的帮助。<br>很多方法延续2D的方法来预测关键点。</p>
<h2 id="2016—CVPR—Deep3DBox"><a href="#2016—CVPR—Deep3DBox" class="headerlink" title="2016—CVPR—Deep3DBox"></a>2016—CVPR—Deep3DBox</h2><p>对于3D框的回归，分成了三个分支。一个分支预测目标框的size相当于一类目标的均值的偏差，另外两个分支用于预测角度。角度的回归使用的是MultiBin的方法，预测每个bin的置信度以及角度的正弦和余弦。得到2D的结果和3D的结果后，使用最小二乘法通过最小化重投影误差计算目标框的位置。<br>缺点在于非常依赖于2D框的精度。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/478741/1668950168695-bbc010be-f9ea-4d70-b406-27cbf1950c11.png#averageHue=%23f7f6e6&amp;clientId=u9c117383-1941-4&amp;from=paste&amp;height=329&amp;id=u1fd5cfaa&amp;originHeight=657&amp;originWidth=816&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=167856&amp;status=done&amp;style=none&amp;taskId=ueb74e161-5352-4983-86d0-e65a9687d6e&amp;title=&amp;width=408" alt="image.png"></p>
<h2 id="2017—CVPR—Deep-MANTA"><a href="#2017—CVPR—Deep-MANTA" class="headerlink" title="2017—CVPR—Deep MANTA"></a>2017—CVPR—Deep MANTA</h2><p>本文是这一方案的先驱。首先使用级联的faster RCNN的架构来回归2D框、分类和模板的相似度。然后使用预先选择好的3D CAD模型，使用EpnP算法进行2D/3D的匹配。</p>
<h2 id="2018—IROS—The-Earth-ain’t-Flat"><a href="#2018—IROS—The-Earth-ain’t-Flat" class="headerlink" title="2018—IROS—The Earth ain’t Flat"></a>2018—IROS—The Earth ain’t Flat</h2><p>本文目标在陡峭和分级的道路上对车辆进行单目重建。一个关键设计在于从单目图像中估计3D shape和6自由度。本文参考Deep MANTA进行3D model的匹配，但不是从所有可能的 3D 形状模板中挑选出最好的一个，而是使用基本向量和变形系数来捕捉车辆的形状。</p>
<h2 id="2019—CVPR—RoI-10D"><a href="#2019—CVPR—RoI-10D" class="headerlink" title="2019—CVPR—RoI-10D"></a>2019—CVPR—RoI-10D</h2><p>10D=6DoF pose + 3DoF size + 1D shape space</p>
<h2 id="2019-AAAI-MonoGRNet"><a href="#2019-AAAI-MonoGRNet" class="headerlink" title="2019-AAAI-MonoGRNet"></a>2019-AAAI-MonoGRNet</h2><p>[<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1811.10247.pdf">Paper</a>]     [<a target="_blank" rel="noopener" href="https://github.com/Zengyi-Qin/MonoGRNet">Code</a>]<br>本文是由多个子网构成的统一网络，包括2D目标检测、实例深度估计、3D定位和局部角回归。<br>pixel-wise的深度估计最小化的是整张图像的所有像素得到一个平均最优估计，一些只占据了很小面积的目标就会被忽略了。<br>本文的核心思想是将3D定位问题解耦成几个循序渐进的子任务。<br>本文回归的是3D中心点的投影和粗糙的实例深度，然后使用两者估计粗糙的3D位置。它强调了2D框的中心点和3D框中心点在2D图像上的投影的不同。<br>本文没有直接回归更好观察的角度，而是回归了8个顶点相对于3D中心点的偏移。</p>
<h2 id="2019-ICCV-MVRA"><a href="#2019-ICCV-MVRA" class="headerlink" title="2019-ICCV-MVRA"></a>2019-ICCV-MVRA</h2><blockquote>
<p>It introduces a 3D reconstruction layer to lift 2D to 3D instead of solving an over-constrained equation, with two losses in two different spaces: 1) IoU loss in perspective view, between the reprojected 3D bbox and the 2d bbox in IoU, and 2) L2 loss in BEV loss between estimated distance and gt distance.<br>It recognizes that deep3DBox does not handle truncated box well, as not four sides of the bounding box now correspond to the real physical extent of the vehicle.</p>
</blockquote>
<h2 id="2019—CVPR—CenterNet—Objects-as-Points"><a href="#2019—CVPR—CenterNet—Objects-as-Points" class="headerlink" title="2019—CVPR—CenterNet—Objects as Points"></a>2019—CVPR—CenterNet—Objects as Points</h2><p>[<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1904.07850.pdf">Paper</a>]     [<a target="_blank" rel="noopener" href="https://github.com/xingyizhou/CenterNet">Code</a>]<br>本文认为许多方法列出全部潜在的目标框是一个计算冗余且不够高效的方案，本文将目标视作single point，利用关键点估计来回归每个目标框的中心点及其其他属性，如size、3D位置、朝向、甚至姿态。<br>在head部分的设计，是通过heatmap得到目标的位置，因此不需要NMS之类的后处理操作，也无需进行目标框的组合。对比anchor-based的方案来说，CenterNet要简单方便许多。</p>
<h2 id="GPP—Ground-Plane-Polling"><a href="#GPP—Ground-Plane-Polling" class="headerlink" title="GPP—Ground Plane Polling"></a>GPP—Ground Plane Polling</h2><p>本文使用3D框标注生成虚拟的2D关键点。</p>
<h2 id="2020—RTM3D—Real-time-Monocular-3D-Detection-from-Object-Keypoints-for-Autonomous-Driving"><a href="#2020—RTM3D—Real-time-Monocular-3D-Detection-from-Object-Keypoints-for-Autonomous-Driving" class="headerlink" title="2020—RTM3D—Real-time Monocular 3D Detection from Object Keypoints for Autonomous Driving"></a>2020—RTM3D—Real-time Monocular 3D Detection from Object Keypoints for Autonomous Driving</h2><blockquote>
<p>This article uses virtual keypoints and use CenterNet-like structure to directly detect the 2d projection of all 8 cuboid vertices + cuboid center. The paper also directly regresses distance, orientation, size. Instead of using these values to form cuboids directly, these values are used as the initial values (priors) to initialize the offline optimizer to generate 3D bboxes.</p>
</blockquote>
<h2 id="2020—CVPR—MonoPair—MonoPair-Monocular-3D-Object-Detection-Using-Pairwise-Spatial-Relationships"><a href="#2020—CVPR—MonoPair—MonoPair-Monocular-3D-Object-Detection-Using-Pairwise-Spatial-Relationships" class="headerlink" title="2020—CVPR—MonoPair—MonoPair: Monocular 3D Object Detection Using Pairwise Spatial Relationships"></a>2020—CVPR—MonoPair—MonoPair: Monocular 3D Object Detection Using Pairwise Spatial Relationships</h2><blockquote>
<p>MonoPair considers the pair-wise relationships between neighboring objects, which are utilized as spatial constraints to optimize the results of detection.</p>
</blockquote>
<p>有针对occluded目标进行处理<br>本文考虑了成对的目标之间的空间关系，加入了uncertainty的考虑。<br>Homography Loss for Monocular 3D Object Detection是本文的衍生方案，都使用了graph的方案，考虑了多目标之间的空间约束</p>
<h2 id="2020—CVPRW—SMOKE"><a href="#2020—CVPRW—SMOKE" class="headerlink" title="2020—CVPRW—SMOKE"></a>2020—CVPRW—SMOKE</h2><p>本文完全消除了 2D bbox 的回归并直接预测 3D bbox<br>显著降低了60米以内的distance error</p>
<h2 id="2020—AAAI—Monocular-3D-Object-Detection-with-Decoupled-Structured-Polygon-Estimation-and-Height-Guided-Depth-Estimation"><a href="#2020—AAAI—Monocular-3D-Object-Detection-with-Decoupled-Structured-Polygon-Estimation-and-Height-Guided-Depth-Estimation" class="headerlink" title="2020—AAAI—Monocular 3D Object Detection with Decoupled Structured Polygon Estimation and Height-Guided Depth Estimation"></a>2020—AAAI—Monocular 3D Object Detection with Decoupled Structured Polygon Estimation and Height-Guided Depth Estimation</h2><blockquote>
<p>The first work to clearly state that the estimation of the 2D projection of the 3D vertices is totally decoupled from the depth estimation.<br>It uses a similar method as RTM3D to regress the eight projected points of the cuboid, then uses vertical edge height as a strong prior to guide distance estimation. This generates a coarse 3D cuboid.</p>
</blockquote>
<h2 id="2021—CVPR—FCOS3D"><a href="#2021—CVPR—FCOS3D" class="headerlink" title="2021—CVPR—FCOS3D"></a>2021—CVPR—FCOS3D</h2><h1 id="Pesudo-LiDAR-and-BEV"><a href="#Pesudo-LiDAR-and-BEV" class="headerlink" title="Pesudo LiDAR and BEV"></a>Pesudo LiDAR and BEV</h1><p>在透视视角下，对于纯视觉的方案存在着遮挡和尺度变化的挑战。一些方法通过转换输入图像的表示形式来应对这个问题。<br>基于Pesudo-LiDAR和BEV的方案实际上都是将输入图像换了一种表示方法，近年来的主流BEV方法也多是借助Pseudo LiDAR的思想再过渡到BEV的表示方式，因此此处合并在一个类别下。</p>
<h2 id="BEV-without-Pseudo-LiDAR"><a href="#BEV-without-Pseudo-LiDAR" class="headerlink" title="BEV without Pseudo LiDAR"></a>BEV without Pseudo LiDAR</h2><p>BEV的表示下，不同的车辆之间不会出现重叠的现象。过去常使用IPM的方式得到BEV的图像，但是这种方案假设所有的像素都在地面上，并且需要获得相机精准的内外参。对于在路上行进的车辆而已，外参是实时变化的，其精度可能无法达到IPM的要求。</p>
<h3 id="2019—IV—Deep-Learning-based-Vehicle-Position-and-Orientation-Estimation-via-Inverse-Perspective-Mapping-Image"><a href="#2019—IV—Deep-Learning-based-Vehicle-Position-and-Orientation-Estimation-via-Inverse-Perspective-Mapping-Image" class="headerlink" title="2019—IV—Deep Learning based Vehicle Position and Orientation Estimation via Inverse Perspective Mapping Image"></a>2019—IV—Deep Learning based Vehicle Position and Orientation Estimation via Inverse Perspective Mapping Image</h3><p>这篇文章使用IMU数据来进行外参的在线标定从而得到更精确的IPM图像，然后在此之上进行目标检测。</p>
<h3 id="2019—BMVC—OFT—Orthographic-Feature-Transform-for-Monocular-3D-Object-Detection"><a href="#2019—BMVC—OFT—Orthographic-Feature-Transform-for-Monocular-3D-Object-Detection" class="headerlink" title="2019—BMVC—OFT—Orthographic Feature Transform for Monocular 3D Object Detection"></a>2019—BMVC—OFT—Orthographic Feature Transform for Monocular 3D Object Detection</h3><p>本文是将透视图转到BEV视角的另一种方式。其思想是利用正交特征变换来将透视视角的图像特征转到正交BEV下。然后通过在投影的voxel area上累加图像特征从而得到voxel-based的特征，再沿着垂直维度折叠voxel feature以产生正交地平面的特征。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/478741/1668776253342-b70b7601-3e96-4dac-8a64-cf251da049cd.png#averageHue=%23f0f0ef&amp;clientId=ud79661c2-ad60-4&amp;from=paste&amp;height=252&amp;id=u1b5fb897&amp;originHeight=252&amp;originWidth=845&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=121370&amp;status=done&amp;style=none&amp;taskId=ue8ddc226-f280-4f9d-b12f-27682a739f7&amp;title=&amp;width=845" alt="image.png"><br>OFT的思路非常简单，效果也很好。</p>
<blockquote>
<p>Although the back-projection step could have been improved by using some heuristics for better initialization of the voxel-based features, rather than naively do a back-projection.<br>review的作者的观点，还需要熟悉一下文章体会一下。</p>
</blockquote>
<h2 id="Pseudo-LiDAR"><a href="#Pseudo-LiDAR" class="headerlink" title="Pseudo LiDAR"></a>Pseudo LiDAR</h2><p>基于Pseudo-LiDAR的方案的实质是根据2D图像估计深度，借助单目深度估计的方案生成点云。</p>
<h3 id="2017—CVPR—MonoDepth—Unsupervised-Monocular-Depth-Estimation-with-Left-Right-Consistency"><a href="#2017—CVPR—MonoDepth—Unsupervised-Monocular-Depth-Estimation-with-Left-Right-Consistency" class="headerlink" title="2017—CVPR—MonoDepth—Unsupervised Monocular Depth Estimation with Left-Right Consistency"></a>2017—CVPR—MonoDepth—Unsupervised Monocular Depth Estimation with Left-Right Consistency</h3><h3 id="2018—CVPR—MLF—Multi-Level-Fusion-based-3D-Object-Detection-from-Monocular-Images"><a href="#2018—CVPR—MLF—Multi-Level-Fusion-based-3D-Object-Detection-from-Monocular-Images" class="headerlink" title="2018—CVPR—MLF—Multi-Level Fusion based 3D Object Detection from Monocular Images"></a>2018—CVPR—MLF—Multi-Level Fusion based 3D Object Detection from Monocular Images</h3><p>本文是严格意义上第一篇提出将估计的深度信息lift到3D的，使用估计的深度信息将每个像素从RGB图像上投影到3D空间，然后再将得到的点云特征和图像特征融合起来得到3D目标框。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/478741/1668777488770-0e5506ce-bde1-4af6-9959-c91a488564c3.png#averageHue=%23e2d2b7&amp;clientId=ud79661c2-ad60-4&amp;from=paste&amp;height=347&amp;id=u3d33257d&amp;originHeight=347&amp;originWidth=777&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=167932&amp;status=done&amp;style=none&amp;taskId=u30e094d5-b500-41b0-ad6e-b52b5c07eec&amp;title=&amp;width=777" alt="image.png"></p>
<h3 id="2018—CVPR—Pseudo-LiDAR-from-Visual-Depth-Estimation-Bridging-the-Gap-in-3D-Object-Detection-for-Autonomous-Driving"><a href="#2018—CVPR—Pseudo-LiDAR-from-Visual-Depth-Estimation-Bridging-the-Gap-in-3D-Object-Detection-for-Autonomous-Driving" class="headerlink" title="2018—CVPR—Pseudo-LiDAR from Visual Depth Estimation: Bridging the Gap in 3D Object Detection for Autonomous Driving"></a>2018—CVPR—Pseudo-LiDAR from Visual Depth Estimation: Bridging the Gap in 3D Object Detection for Autonomous Driving</h3><p>本文在得到Pseudo-LiDAR的特征后，直接使用最新的lidar-based的3D检测器。</p>
<blockquote>
<p> The authors argue that representation matters, and convolution on depth map does not make sense, as neighboring pixels on depth images may be physically far away in 3D space.<br>review</p>
</blockquote>
<h3 id="2018—CVPR—Frustum-PointNets-for-3D-Object-Detection-from-RGB-D-Data"><a href="#2018—CVPR—Frustum-PointNets-for-3D-Object-Detection-from-RGB-D-Data" class="headerlink" title="2018—CVPR—Frustum PointNets for 3D Object Detection from RGB-D Data"></a>2018—CVPR—Frustum PointNets for 3D Object Detection from RGB-D Data</h3><p><img src="https://cdn.nlark.com/yuque/0/2022/png/478741/1668848902425-3d8dbb09-3d3b-4de1-81d4-d22cf6ddf968.png#averageHue=%23d4d0cb&amp;clientId=uf53aa924-d691-4&amp;from=paste&amp;height=263&amp;id=u51387129&amp;originHeight=263&amp;originWidth=661&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=176617&amp;status=done&amp;style=none&amp;taskId=u884520b7-fa04-4ac1-9341-8dc357a6e72&amp;title=&amp;width=661" alt="image.png"></p>
<h3 id="2019—ICCV—Monocular-3D-Object-Detection-with-Pseudo-LiDAR-Point-Cloud"><a href="#2019—ICCV—Monocular-3D-Object-Detection-with-Pseudo-LiDAR-Point-Cloud" class="headerlink" title="2019—ICCV—Monocular 3D Object Detection with Pseudo-LiDAR Point Cloud"></a>2019—ICCV—Monocular 3D Object Detection with Pseudo-LiDAR Point Cloud</h3><p>本文提出了pseudo-lidar的方案的两个缺点：不准确的深度估计导致的local misalignment 和目标外围深度伪影导致的long tail。提出了实例分割mask，并引入了2D-3D框的consistency loss。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/478741/1668848848450-f7427826-075c-413b-8f55-1ad7bd4487f1.png#averageHue=%23faf2cd&amp;clientId=uf53aa924-d691-4&amp;from=paste&amp;height=414&amp;id=u3315ef35&amp;originHeight=827&amp;originWidth=508&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=418515&amp;status=done&amp;style=none&amp;taskId=uf6b88a11-2464-4136-a612-36d07177c01&amp;title=&amp;width=254" alt="image.png"></p>
<h3 id="ForeSeE"><a href="#ForeSeE" class="headerlink" title="ForeSeE"></a>ForeSeE</h3><p>ForeSeE 也注意到了这些缺点，它们提出不是所有的pixel在深度估计中都有相同的重要性。因此它们训练了两个不同的深度估计器，一个用于前景、一个用于背景。在推理的时候自适应的融合深度图。</p>
<h3 id="2019—ICCV—AM3D—Accurate-Monocular-3D-Object-Detection-via-Color-Embedded-3D-Reconstruction-for-Autonomous-Driving"><a href="#2019—ICCV—AM3D—Accurate-Monocular-3D-Object-Detection-via-Color-Embedded-3D-Reconstruction-for-Autonomous-Driving" class="headerlink" title="2019—ICCV—AM3D—Accurate Monocular 3D Object Detection via Color-Embedded 3D Reconstruction for Autonomous Driving"></a>2019—ICCV—AM3D—Accurate Monocular 3D Object Detection via Color-Embedded 3D Reconstruction for Autonomous Driving</h3><blockquote>
<p>AM3D proposes a multi-modal fusion module to enhance the pseudo-LiDAR with color information</p>
</blockquote>
<h3 id=""><a href="#" class="headerlink" title=" "></a> </h3><h3 id="202008—ECCV2020—PatchNet—Rethinking-Pseudo-LiDAR-Representation"><a href="#202008—ECCV2020—PatchNet—Rethinking-Pseudo-LiDAR-Representation" class="headerlink" title="202008—ECCV2020—PatchNet—Rethinking Pseudo-LiDAR Representation"></a>202008—ECCV2020—PatchNet—Rethinking Pseudo-LiDAR Representation</h3><blockquote>
<p>PatchNet organizes pseudo-LiDAR into the image representation and utilizes powerful 2D CNN to boost the detection performance.<br>MonoFlex</p>
</blockquote>
<h3 id="202103—ICCV—Are-we-Missing-Confidence-in-Pseudo-LiDAR-Methods-for-Monocular-3D-Object-Detection"><a href="#202103—ICCV—Are-we-Missing-Confidence-in-Pseudo-LiDAR-Methods-for-Monocular-3D-Object-Detection" class="headerlink" title="202103—ICCV—Are we Missing Confidence in Pseudo-LiDAR Methods for Monocular 3D Object Detection?"></a>202103—ICCV—Are we Missing Confidence in Pseudo-LiDAR Methods for Monocular 3D Object Detection?</h3><p>本文认为虽然PL-based的方法表现出比RGB image only的方法更好的指标，但是并不意味着PL-based的方法是完全优于后者的，其中还有KITTI数据集中存在的问题。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/478741/1668346439612-8e3d2178-e242-48a5-9737-8bc6d41d4143.png#averageHue=%2375e692&amp;clientId=u137eae7a-36b8-4&amp;from=paste&amp;height=574&amp;id=uc9dccc1a&amp;originHeight=574&amp;originWidth=678&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=141185&amp;status=done&amp;style=none&amp;taskId=u5d0519b3-35da-44f3-9086-715356b9b33&amp;title=&amp;width=678" alt="image.png"></p>
<h3 id="2021—CVPR—Objects-are-Different-Flexible-Monocular-3D-Object-Detection"><a href="#2021—CVPR—Objects-are-Different-Flexible-Monocular-3D-Object-Detection" class="headerlink" title="2021—CVPR—Objects are Different: Flexible Monocular 3D Object Detection"></a>2021—CVPR—Objects are Different: Flexible Monocular 3D Object Detection</h3><p>MonoFlex针对截断目标设计了不同的3D目标框解耦方式</p>
<p>DD3D</p>
<h3 id="2022—CVPR—Homography-Loss-for-Monocular-3D-Object-Detection"><a href="#2022—CVPR—Homography-Loss-for-Monocular-3D-Object-Detection" class="headerlink" title="2022—CVPR—Homography Loss for Monocular 3D Object Detection"></a>2022—CVPR—Homography Loss for Monocular 3D Object Detection</h3><p><img src="https://cdn.nlark.com/yuque/0/2022/png/478741/1668655897144-c7dab5f8-4ebe-4bad-b72b-c24c85c71505.png#averageHue=%23f6f6f5&amp;clientId=udc62ad13-1138-4&amp;from=drop&amp;id=ub50b52a1&amp;originHeight=312&amp;originWidth=1174&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=149118&amp;status=done&amp;style=none&amp;taskId=uc423b1ad-7ac0-4635-b41d-40a973f2216&amp;title=" alt="截屏2022-11-17 11.31.32.png"></p>
<h1 id="Related-Review"><a href="#Related-Review" class="headerlink" title="Related Review"></a>Related Review</h1><p>XPeng—-Patrick Langechuan Liu—-2020<br><a target="_blank" rel="noopener" href="https://towardsdatascience.com/monocular-3d-object-detection-in-autonomous-driving-2476a3c7f57e">Monocular 3D Object Detection in Autonomous Driving — A Review</a></p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">Jingyi Yu</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://massive11.github.io/2022/08/12/Paper-Mono3D%20paper%E8%B7%AF%E7%BA%BF%E6%A2%B3%E7%90%86/">https://massive11.github.io/2022/08/12/Paper-Mono3D%20paper%E8%B7%AF%E7%BA%BF%E6%A2%B3%E7%90%86/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">Jingyi Yu</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Mono3D/">
                                    <span class="chip bg-color">Mono3D</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2022/08/22/Paper-PGD-Probabilistic%20and%20Geometric%20Depth_%20Detecting%20Objects%20in%20Perspective/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/5.jpg" class="responsive-img" alt="PGD-Probabilistic and Geometric Depth_ Detecting Objects in Perspective">
                        
                        <span class="card-title">PGD-Probabilistic and Geometric Depth_ Detecting Objects in Perspective</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            本文整理了Probabilistic and Geometric Depth_ Detecting Objects in Perspective论文主要内容
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2022-08-22
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Paper/" class="post-category">
                                    Paper
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Multi-view-3D/">
                        <span class="chip bg-color">Multi-view 3D</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2022/07/26/Paper-BEV%E6%A8%A1%E5%9E%8B%E6%B7%B1%E5%BA%A6%E4%BC%B0%E8%AE%A1%E6%A8%A1%E5%9D%97Overview/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/14.jpg" class="responsive-img" alt="BEV模型深度估计模块Overview">
                        
                        <span class="card-title">BEV模型深度估计模块Overview</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            本文对BEV模型深度估计模块进行了梳理。
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2022-07-26
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E7%B3%BB%E7%BB%9F%E6%A2%B3%E7%90%86/" class="post-category">
                                    系统梳理
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Multi-view-3D/">
                        <span class="chip bg-color">Multi-view 3D</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>


  <!-- 是否加载使用自带的 prismjs. -->
  <script type="text/javascript" src="/libs/prism/prism.min.js"></script>


<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2020-2023</span>
            
            <a href="/about" target="_blank">Jingyi Yu</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">29.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2020";
                        var startMonth = "3";
                        var startDate = "28";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/massive11" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:1005625333@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>













</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
